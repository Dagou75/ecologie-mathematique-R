[
["chapitre-biostats-bayes.html", "6 Introduction à l’analyse bayésienne en écologie 6.1 Qu’est-ce que c’est? 6.2 Pourquoi utiliser? 6.3 Comment l’utiliser? 6.4 Faucons pélerins 6.5 Statistiques d’une population 6.6 Test de t: Différence entre des groupes 6.7 Pour aller plus loin", " 6 Introduction à l’analyse bayésienne en écologie Les statistiques bayésiennes forment une trousse d’outils à garder dans votre pack sack. 6.1 Qu’est-ce que c’est? En deux mots: modélisation probabiliste. Un approche de modélisation probabiliste se servant au mieux de l’information disponible. Pour calculer les probabilités d’une variable inconnu en mode bayésien, nous avons besoin: De données D’un modèle D’une idée plus ou moins précise du résultat avant d’avoir analysé les données De manière plus formelle, le théorème de Bayes (qui forme la base de l’analyse bayéseienne), dit que la distribution de probabilité des paramètres d’un modèle (par exemple, la moyenne ou une pente) est proportionnelle à la mutliplication de la distribution de probabilité estimée des paramètres et la distribution de probabilité émergeant des données. Plus formellement, \\[P\\left(\\theta | y \\right) = \\frac{P\\left(y | \\theta \\right) \\times P\\left(\\theta\\right)}{P\\left(y \\right)}\\], où \\(P\\left(\\theta | y \\right)\\) \\(-\\) la probabilité d’obtenir des paramètres \\(\\theta\\) à partir des données \\(y\\) \\(-\\) est la distribution de probabilité a posteriori, calculée à partir de votre a prioti \\(P\\left(\\theta\\right)\\) \\(-\\) la probabilité d’obtenir des paramètres \\(\\theta\\) sans égard aux données, selon votre connaissance du phénomène \\(-\\) et vos données observées \\(P\\left(y | \\theta \\right)\\) \\(-\\) la probabilité d’obtenir les données \\(y\\) étant donnés les paramètres \\(\\theta\\) qui régissent le phénomène. \\(P\\left(y\\right)\\), la probabilité d’observer les données, est appellée la vraissemblance marginale, et assure que la somme des probabilités est nulle. 6.2 Pourquoi utiliser? Avec la notion fréquentielle de probabilité, on teste la probabilité d’observer les données recueillies étant donnée l’absence d’effet réel (qui est l’hypothèse nulle généralement adoptée). La notion bayésienne de probabilité combine la connaissance que l’on a d’un phénomène et les données observées pour estimer la probabilité qu’il existe un effet réel. En d’autre mots, les stats fréquentielles testent si les données concordent avec un modèle du réel, tandis que les stats bayésiennes évaluent la probabilité que le modèle soit réel. Le hic, c’est que lorsqu’on utilise les statistiques fréquentielles pour répondre à une question bayésienne, on s’expose à de mauvaises interprétations. Si l’on désire, par exemple, évaluer la probabilité de l’existance de vie sur Mars, on devra passer par le bayésien, car avec les stats fréquentielles, l’on devra plutpot conclure si les données sont conforme ou non avec l’hypothèse de la vie sur Mars (exemple tirée du blogue Dynamic Ecology). 6.3 Comment l’utiliser? Bien que la formule du théorème de Bayes soit plutôt simple, calculer une fonction a posteriori demandera de passer par des algorithmes de simulation, ce qui pourrait demander une bonne puissance de calcul, et des outils appropriés. En particulier, le module générique greta permet de générer une panoplie de modèles bayésiens. Pour installer greta, vous devez préalablement installer Python, gréé des modules tensorflow et tensorflow-probability en suivant le guide. En somme, vous devez d’abord installer greta (install.packages(&quot;greta&quot;)). Puis vous devez installer une distribution de Python – je vous suggère Anaconda (~500 Mo) ou Miniconda pour une installation minimale (~60 Mo). Enfin, lancez les commandes suivantes (une connection internet est nécessaire pour télécharger les modules). ``` install_tensorflow(method = “conda”) reticulate::conda_install(“r-tensorflow”, “tensorflow-probability”, pip = TRUE) ``` 6.4 Faucons pélerins Empruntons un exemple du livre Introduction to WinBUGS for Ecologists: A Bayesian Approach to Regression, ANOVA and Related Analyses, de Marc Kéry et examinons la masse de faucons pélerins. Mais alors que Marc Kéry utilise WinBUGS, un logiciel de résolution de problème en mode bayésien, nous utiliserons greta. Source: Wikimedia Commons Pour une première approche, nous allons estimer la masse moyenne d’une population de faucons pélerins. À titre de données, générons des nombres aléatoires. Cette stratégie permet de valider les statistiques en les comparant aux paramètre que l’on impose. Ici, nous imposons une moyenne de 600 grammes et un écart-type de 30 grammes. Générons une séries de données avec 20 échantillons. library(&quot;tidyverse&quot;) ## ── Attaching packages ──────────────────────────────────────────────────── tidyverse 1.2.1 ── ## ✔ ggplot2 3.1.0 ✔ purrr 0.2.5 ## ✔ tibble 1.4.2 ✔ dplyr 0.7.8 ## ✔ tidyr 0.8.2 ✔ stringr 1.3.1 ## ✔ readr 1.1.1 ✔ forcats 0.3.0 ## ── Conflicts ─────────────────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() set.seed(5682) y20 &lt;- rnorm(n = 20, mean=600, sd = 30) y200 &lt;- rnorm(n = 200, mean=600, sd = 30) par(mfrow = c(1, 2)) hist(y20, breaks=5) hist(y200, breaks=20) Je crée une fonction qui retourne la moyenne et l’erreur sur la moyenne ou sur la distribution. Calculons les statistiques classiques. confidence_interval &lt;- function(x, on=&quot;deviation&quot;, distribution=&quot;t&quot;, level=0.95) { m &lt;- mean(x) se &lt;- sd(x) n &lt;- length(x) if (distribution == &quot;t&quot;) { error &lt;- se * qt((1+level)/2, n-1) } else if (distribution == &quot;normal&quot;) { error &lt;- se * qnorm((1+level)/2) } if (on == &quot;error&quot;) { error &lt;- error/sqrt(n) } return(c(ll = m-error, mean = m, ul = m+error)) } print(&quot;Déviation, 95%&quot;) ## [1] &quot;Déviation, 95%&quot; print(round(confidence_interval(y20, on=&#39;deviation&#39;, level=0.95), 2)) ## ll mean ul ## 532.23 598.85 665.47 print(&quot;Erreur, 95%&quot;) ## [1] &quot;Erreur, 95%&quot; print(round(confidence_interval(y20, on=&#39;error&#39;, level=0.95), 2)) ## ll mean ul ## 583.96 598.85 613.75 print(&quot;Écart-type&quot;) ## [1] &quot;Écart-type&quot; print(round(sd(y20), 2)) ## [1] 31.83 En faisant cela, nous prenons pour acquis que les données sont distribuées normalement. En fait, nous savons qu’elles devraient l’être pour de grands échantillons, puisque nous avons nous-même généré les données. Par contre, comme observateur par exemple de la série de 20 données générées, la distribution est définitivement asymétrique. Sous cet angle, la moyenne, ainsi que l’écart-type, pourraient être des paramètres biaisés. Nous pouvons justifier le choix d’une loi normale par des connaissances a priori des distributions de masse parmi des espèces d’oiseau. Ou bien transformer les données pour rendre leur distribution normale (chapitre 7). 6.5 Statistiques d’une population 6.5.1 greta En mode bayésien, nous devons définir la connaissance a priori sous forme de variables aléatoires non-observées selon une distribution. Prenons l’exemple des faucons pélerins. Disons que nous ne savons pas à quoi ressemble la moyenne du groupe a priori. Nous pouvons utiliser un a priori vague, où la masse moyenne peut prendre n’importe quelle valeur entre 0 et 2000 grammes, sans préférence: nous lui imposons donc un a priori selon une distribution uniforme. Idem pour l’écart-type library(&quot;greta&quot;) ## ## Attaching package: &#39;greta&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## slice ## The following objects are masked from &#39;package:stats&#39;: ## ## binomial, cov2cor, poisson ## The following objects are masked from &#39;package:base&#39;: ## ## %*%, apply, backsolve, beta, chol2inv, colMeans, colSums, ## diag, eigen, forwardsolve, gamma, identity, rowMeans, rowSums, ## sweep, tapply library(&quot;DiagrammeR&quot;) library (&quot;bayesplot&quot;) ## This is bayesplot version 1.6.0 ## - Online documentation and vignettes at mc-stan.org/bayesplot ## - bayesplot theme set to bayesplot::theme_default() ## * Does _not_ affect other ggplot2 plots ## * See ?bayesplot_theme_set for details on theme setting library(&quot;tidybayes&quot;) ## NOTE: As of tidybayes version 1.0, several functions, arguments, and output column names ## have undergone significant name changes in order to adopt a unified naming scheme. ## See help(&#39;tidybayes-deprecated&#39;) for more information. param_mean &lt;- uniform(min = 0, max = 2000) param_sd &lt;- uniform(min = 0, max = 100) La fonction a porteriori inclue la fonction de vraissemblance ainsi que la connaissancew a priori. distribution(y20) &lt;- normal(param_mean, param_sd) Le tout forme un modèle pour apprécier y, la masse des faucons pélerins. m &lt;- model(param_mean, param_sd) plot(m) Légende: Nous pouvons enfin lancer le modèle . draws &lt;- mcmc(m, n_samples = 1000) ## ## running 4 chains simultaneously on up to 4 cores ## warmup 0/1000 | eta: ?s warmup == 50/1000 | eta: 18s warmup ==== 100/1000 | eta: 12s warmup ====== 150/1000 | eta: 10s warmup ======== 200/1000 | eta: 8s warmup ========== 250/1000 | eta: 7s warmup =========== 300/1000 | eta: 7s warmup ============= 350/1000 | eta: 6s warmup =============== 400/1000 | eta: 6s warmup ================= 450/1000 | eta: 5s warmup =================== 500/1000 | eta: 5s warmup ===================== 550/1000 | eta: 4s warmup ======================= 600/1000 | eta: 4s warmup ========================= 650/1000 | eta: 3s warmup =========================== 700/1000 | eta: 3s warmup ============================ 750/1000 | eta: 2s warmup ============================== 800/1000 | eta: 2s warmup ================================ 850/1000 | eta: 1s warmup ================================== 900/1000 | eta: 1s warmup ==================================== 950/1000 | eta: 0s warmup ====================================== 1000/1000 | eta: 0s ## sampling 0/1000 | eta: ?s sampling == 50/1000 | eta: 4s sampling ==== 100/1000 | eta: 4s sampling ====== 150/1000 | eta: 3s sampling ======== 200/1000 | eta: 3s sampling ========== 250/1000 | eta: 3s sampling =========== 300/1000 | eta: 3s sampling ============= 350/1000 | eta: 3s sampling =============== 400/1000 | eta: 3s sampling ================= 450/1000 | eta: 2s sampling =================== 500/1000 | eta: 2s sampling ===================== 550/1000 | eta: 2s sampling ======================= 600/1000 | eta: 2s sampling ========================= 650/1000 | eta: 2s sampling =========================== 700/1000 | eta: 1s sampling ============================ 750/1000 | eta: 1s sampling ============================== 800/1000 | eta: 1s sampling ================================ 850/1000 | eta: 1s sampling ================================== 900/1000 | eta: 0s sampling ==================================== 950/1000 | eta: 0s sampling ====================================== 1000/1000 | eta: 0s L’inspection de l’échantillonnage peut être effectuée grâce au module bayesplot. mcmc_combo(draws, combo = c(&quot;hist&quot;, &quot;trace&quot;)) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. L’échantillonnage semble stable. Voyons la distribution a posteriori des paramètres. draws_tidy &lt;- draws %&gt;% spread_draws(param_mean, param_sd) print(&quot;Moyenne:&quot;) ## [1] &quot;Moyenne:&quot; confidence_interval(x = draws_tidy$param_mean, on = &quot;deviation&quot;, distribution = &quot;normal&quot;, level = 0.95) ## ll mean ul ## 583.6427 599.1018 614.5610 print(&quot;Écart-type:&quot;) ## [1] &quot;Écart-type:&quot; confidence_interval(x = draws_tidy$param_sd, on = &quot;deviation&quot;, distribution = &quot;normal&quot;, level = 0.95) ## ll mean ul ## 22.12636 34.26526 46.40416 L’a priori étant vague, les résultats de l’analyse bayésienne sont comparables aux statistiques fréquentielles. print(&quot;Erreur, 95%&quot;) ## [1] &quot;Erreur, 95%&quot; print(round(confidence_interval(y20, on=&#39;error&#39;, level=0.95), 2)) ## ll mean ul ## 583.96 598.85 613.75 Les résultats des deux approches peuvent néanmoins être interprétés de manière différente. En ce qui a trait à la moyenne: Fréquentiel. Il y a une probabilité de 95% que mes données aient été générées à partir d’une moyenne se situant entre 584 et 614 grammes. Bayésien. Étant donnée mes connaissances (vagues) de la moyenne et de l’écart-type avant de procéder à l’analyse (a priori), il y a une probabilité de 95% que la moyenne de la masse de la population se situe entre 583 et 614 grammes. Nous avons maintenant une idée de la distribution de moyenne de la population. Mais, rarement, une analyse s’arrêtera à ce stade. Il arrive souvent que l’on doive comparer les pparamètres de deux, voire plusieurs groupes. Par exemple, comparer des populations vivants dans des écosystèmes différents, ou comparer un traitement à un placébo. Ou bien, comparer, dans une même population de faucons pélerins, l’envergure des ailes des mâles et celle des femelles. 6.6 Test de t: Différence entre des groupes Pour comparer des groupes, on exprime généralement une hypothèse nulle, qui typiquement pose qu’il n’y a pas de différence entre les groupes. Puis, on choisit un test statistique pour déterminer si les distributions des données observées sont plausibles dans si l’hypothèse nulle est vraie. En d’autres mots, le test statistique exprime la probabilité que l’on obtienne les données obtenues s’il n’y avait pas de différence entre les groupes. Par exemple, si vous obtenez une p-value de moins de 0.05 après un test de comparaison et l’hypothèse nulle pose qu’il n’y a pas de différence entre les groupes, cela signifie qu’il y a une probabilité de 5% que vous ayiez obtenu ces données s’il n’y avait en fait pas de différence entre les groupe. Il serait donc peu probable que vos données euent été générées comme telles s’il n’y avait en fait pas de différence. n_f &lt;- 30 moy_f &lt;- 105 n_m &lt;- 20 moy_m &lt;- 77.5 sd_fm &lt;- 2.75 set.seed(21526) envergure_f &lt;- rnorm(mean=moy_f, sd=sd_fm, n=n_f) envergure_m &lt;- rnorm(mean=moy_m, sd=sd_fm, n=n_m) envergure_f_df &lt;- data.frame(Sex = &quot;Female&quot;, Wingspan = envergure_f) envergure_m_df &lt;- data.frame(Sex = &quot;Male&quot;, Wingspan = envergure_m) envergure_df &lt;- rbind(envergure_f_df, envergure_m_df) envergure_df %&gt;% ggplot(aes(x=Wingspan)) + geom_histogram(aes(y=..density.., fill=Sex)) + geom_density(aes(linetype=Sex, y=..density..)) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Et les statistiques des deux groupesL envergure_df %&gt;% group_by(Sex) %&gt;% summarise(mean = mean(Wingspan), sd = sd(Wingspan), n = n()) ## # A tibble: 2 x 4 ## Sex mean sd n ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Female 105. 2.46 30 ## 2 Male 77.0 3.19 20 Évaluer s’il y a une différence significative peut se faire avec un test de t (ou de Student). t.test(envergure_f, envergure_m) ## ## Welch Two Sample t-test ## ## data: envergure_f and envergure_m ## t = 33.235, df = 33.665, p-value &lt; 2.2e-16 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 26.29232 29.71848 ## sample estimates: ## mean of x mean of y ## 105.04267 77.03727 La probabilité que les données ait été générées de la sorte si les deux groupes n’était semblables est très faible (p-value &lt; 2.2e-16). On obtiendrait sensiblement les mêmes résultats avec une régression linéaire. linmod &lt;- lm(Wingspan ~ Sex, envergure_df) summary(linmod) ## ## Call: ## lm(formula = Wingspan ~ Sex, data = envergure_df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -8.221 -1.938 0.219 2.046 4.686 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 105.0427 0.5062 207.51 &lt;2e-16 *** ## SexMale -28.0054 0.8004 -34.99 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.773 on 48 degrees of freedom ## Multiple R-squared: 0.9623, Adjusted R-squared: 0.9615 ## F-statistic: 1224 on 1 and 48 DF, p-value: &lt; 2.2e-16 Le modèle linéaire est plus informatif. Il nous apprend que l’envergure des ailes des mâles est en moyenne plus faible de 28.0 cm que celle des femelles… confint(linmod, level = 0.95) ## 2.5 % 97.5 % ## (Intercept) 104.02487 106.06047 ## SexMale -29.61468 -26.39612 … avec un intervalle de confiance entre -29.6 cm à -26.4 cm. Utilisons l’information dérivée de statistiques classiques dans nos a priori. Oui-oui, on peut faire ça. Mais attention, un a priori trop précis ou trop collé sur nos données orientera le modèle vers une solution préalablement établie: ce qui constituerait aucune avancée par rapport à l’a priori. Nous allons utiliser a priori pour les deux groupes la moyenne des deux groupes, et comme dispersion la moyenne le double de l’écart-type. Rappelons que cet écart-type est l’a priori de écart-type sur la moyenne, non pas de la population. Procédons à la création d’un modèle greta. Nous utiliserons la régression linéaire préférablement au test de t. is_female &lt;- model.matrix(~envergure_df$Sex)[, 2] int &lt;- normal(600, 30) coef &lt;- normal(30, 10) sd &lt;- cauchy(0, 10, truncation = c(0, Inf)) mu &lt;- int + coef * is_female distribution(envergure_df$Wingspan) &lt;- normal(mu, sd) m &lt;- model(int, coef, sd, mu) plot(m) Go! draws &lt;- mcmc(m, n_samples = 1000) ## ## running 4 chains simultaneously on up to 4 cores ## warmup 0/1000 | eta: ?s warmup == 50/1000 | eta: 21s | 18% bad warmup ==== 100/1000 | eta: 15s | 9% bad warmup ====== 150/1000 | eta: 13s | 6% bad warmup ======== 200/1000 | eta: 11s | 4% bad warmup ========== 250/1000 | eta: 10s | 4% bad warmup =========== 300/1000 | eta: 9s | 3% bad warmup ============= 350/1000 | eta: 8s | 3% bad warmup =============== 400/1000 | eta: 7s | 2% bad warmup ================= 450/1000 | eta: 7s | 2% bad warmup =================== 500/1000 | eta: 6s | 2% bad warmup ===================== 550/1000 | eta: 5s | 2% bad warmup ======================= 600/1000 | eta: 5s | 2% bad warmup ========================= 650/1000 | eta: 5s | 1% bad warmup =========================== 700/1000 | eta: 4s | 1% bad warmup ============================ 750/1000 | eta: 3s | 1% bad warmup ============================== 800/1000 | eta: 2s | 1% bad warmup ================================ 850/1000 | eta: 2s | 1% bad warmup ================================== 900/1000 | eta: 1s | 1% bad warmup ==================================== 950/1000 | eta: 1s | &lt;1% bad warmup ====================================== 1000/1000 | eta: 0s | &lt;1% bad ## sampling 0/1000 | eta: ?s sampling == 50/1000 | eta: 4s sampling ==== 100/1000 | eta: 5s sampling ====== 150/1000 | eta: 5s sampling ======== 200/1000 | eta: 5s sampling ========== 250/1000 | eta: 5s sampling =========== 300/1000 | eta: 4s sampling ============= 350/1000 | eta: 4s sampling =============== 400/1000 | eta: 4s sampling ================= 450/1000 | eta: 4s sampling =================== 500/1000 | eta: 3s sampling ===================== 550/1000 | eta: 3s sampling ======================= 600/1000 | eta: 3s sampling ========================= 650/1000 | eta: 2s sampling =========================== 700/1000 | eta: 2s sampling ============================ 750/1000 | eta: 2s sampling ============================== 800/1000 | eta: 1s sampling ================================ 850/1000 | eta: 1s sampling ================================== 900/1000 | eta: 1s sampling ==================================== 950/1000 | eta: 0s sampling ====================================== 1000/1000 | eta: 0s Et les résultats. mcmc_combo(draws, combo = c(&quot;dens&quot;, &quot;trace&quot;), pars = c(&quot;int&quot;, &quot;coef&quot;, &quot;sd&quot;)) draws_tidy &lt;- draws %&gt;% spread_draws(int, coef, sd) draws_tidy ## # A tibble: 4,000 x 6 ## .chain .iteration .draw int coef sd ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 1 105. -28.8 2.32 ## 2 1 2 2 105. -26.9 2.65 ## 3 1 3 3 106. -27.9 2.43 ## 4 1 4 4 105. -27.0 2.79 ## 5 1 5 5 106. -28.8 2.97 ## 6 1 6 6 105. -27.8 2.43 ## 7 1 7 7 105. -28.2 2.45 ## 8 1 8 8 105. -27.6 2.49 ## 9 1 9 9 105. -28.2 2.62 ## 10 1 10 10 105. -27.9 3.03 ## # ... with 3,990 more rows print(&quot;Intercept:&quot;) ## [1] &quot;Intercept:&quot; confidence_interval(x = draws_tidy$int, on = &quot;deviation&quot;, distribution = &quot;normal&quot;, level = 0.95) ## ll mean ul ## 104.0278 105.0478 106.0678 print(&quot;Pente:&quot;) ## [1] &quot;Pente:&quot; confidence_interval(x = draws_tidy$coef, on = &quot;deviation&quot;, distribution = &quot;normal&quot;, level = 0.95) ## ll mean ul ## -29.38090 -27.77528 -26.16965 6.7 Pour aller plus loin Le module greta est conçu et maintenu par Nick Golding, du Quantitative &amp; Applied Ecology Group de l’University of Melbourne, Australie. La documentation de greta offre des recettes pour toutes sortes d’analyses en écologie. Les livres de Mark Kéry, bien que rédigés pour les calculs en langage R et WinBUGS, offre une approche bien structurée et traduisible en greta, qui est plus moderne que WinBUGS. Introduction to WinBUGS for Ecologists (2010) Bayesian Population Analysis using WinBUGS: A Hierarchical Perspective (2011) Applied Hierarchical Modeling in Ecology: Analysis of distribution, abundance and species richness in R and BUGS (2015) "]
]
